{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wine_classification-KNN_RandomForest_quality.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNNJdg1b67-u"
      },
      "source": [
        "# prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP3WHZK172bm"
      },
      "source": [
        "# load libraries\r\n",
        "import pandas as pd \r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from collections import Counter\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import accuracy_score "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgmOnxe47EMN"
      },
      "source": [
        "# ======================================== prepare dataset\r\n",
        "red_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep= ';')\r\n",
        "white_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep= ';')\r\n",
        "\r\n",
        "red_wine.astype('int64').dtypes\r\n",
        "white_wine.astype('int64').dtypes\r\n",
        "\r\n",
        "## create a new variable 'wine_type'\r\n",
        "red_wine['wine_type'] = 'red'\r\n",
        "\r\n",
        "# bucket wine quality scores into qualitative quality labels\r\n",
        "red_wine['quality_label'] = red_wine['quality'].apply(lambda value: 'low'\r\n",
        "if value <= 5 else 'medium'\r\n",
        "if value <= 7 else 'high')\r\n",
        "red_wine\r\n",
        "\r\n",
        "red_wine['quality_label'] = pd.Categorical(red_wine['quality_label'],\r\n",
        "categories=['low', 'medium', 'high'])\r\n",
        "red_wine['quality_label'].dtype\r\n",
        "\r\n",
        "# create a new variable 'wine_type'\r\n",
        "white_wine['wine_type'] = 'white'\r\n",
        "\r\n",
        "# bucket wine quality scores into qualitative quality labels\r\n",
        "\r\n",
        "white_wine['quality_label'] = white_wine['quality'].apply(lambda value: 'low'\r\n",
        "if value <= 5 else 'medium'\r\n",
        "if value <= 7 else 'high')\r\n",
        "\r\n",
        "white_wine['quality_label'] = pd.Categorical(white_wine['quality_label'],\r\n",
        "categories=['low', 'medium', 'high'])\r\n",
        "\r\n",
        "white_wine\r\n",
        "\r\n",
        "# combine two dataframe (red_wine) & (white_wine)\r\n",
        "wines = pd.concat([red_wine, white_wine])\r\n",
        "\r\n",
        "# re-shuffle records just to randomize data points\r\n",
        "wines = wines.sample(frac=1, random_state=42).reset_index(drop=True)\r\n",
        "wines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTJ9APzziA3E"
      },
      "source": [
        "# preprocessing - IV/DV, data split, feature scaling (feature selection)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLeQiDfBhtxS"
      },
      "source": [
        "# preprocessing - categorical DV : string to numeric \r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "X = wines[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']]\r\n",
        "\r\n",
        "# label encoder: https://www.mygreatlearning.com/blog/label-encoding-in-python/#labelencodingusingpython \r\n",
        "labelencoder = LabelEncoder()\r\n",
        "wines['wine_type_N'] = labelencoder.fit_transform(wines['wine_type']) #red: 0, white: 1\r\n",
        "wines['wine_quality_N'] = labelencoder.fit_transform(wines['quality_label']) #high:0, low:1, medium:2 "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbPS9k9c6653",
        "outputId": "ba84a902-7865-4491-e2e8-8ec6430d4b8c"
      },
      "source": [
        "# =======preprocessing : prepare dataset for classification\r\n",
        "w_features = wines.iloc[:,:-5]\r\n",
        "w_feature_names = w_features.columns\r\n",
        "\r\n",
        "# set IV and DV\r\n",
        "X = w_features\r\n",
        "y = wines['quality_label']\r\n",
        "#y = w_features['wine_type']\r\n",
        "\r\n",
        "# split dataset for predicting wine quality\r\n",
        "wq_train_X, wq_test_X, wq_train_y, wq_test_y = train_test_split(X, y, test_size=0.3, random_state=42)\r\n",
        "print(Counter(wq_train_y), Counter(wq_test_y))\r\n",
        "print('Features:', list(w_feature_names))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'medium': 2737, 'low': 1666, 'high': 144}) Counter({'medium': 1178, 'low': 718, 'high': 54})\n",
            "Features: ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igFykKjvWYkA"
      },
      "source": [
        "# standardization\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "#scaler = MinMaxScaler()\r\n",
        "sc = StandardScaler()\r\n",
        "X = np.array(X)\r\n",
        "\r\n",
        "sc.fit_transform(wq_train_X)\r\n",
        "sc.transform(wq_test_X)\r\n",
        "# why different transformation for train/test set? https://datascience.stackexchange.com/questions/12321/whats-the-difference-between-fit-and-fit-transform-in-scikit-learn-models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZtUEqI3gdN_",
        "outputId": "17ba4414-85f9-46be-bac3-eca1d595c8e4"
      },
      "source": [
        "#select top10 features - option2: randomforest \r\n",
        "#Random Forests and decision trees, in general, give preference to features with high cardinality ( Trees are biased to these type of variables ).\r\n",
        "#Correlated features will be given equal or similar importance, but overall reduced importance compared to the same tree built without correlated counterparts.\r\n",
        "#https://towardsdatascience.com/feature-selection-using-random-forest-26d7b747597f\r\n",
        "from sklearn.ensemble.forest import RandomForestClassifier\r\n",
        "from sklearn.feature_selection import SelectFromModel\r\n",
        "\r\n",
        "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\r\n",
        "sel.fit(wq_train_X, wq_train_y)\r\n",
        "\r\n",
        "sel.get_support()\r\n",
        "selected_feat= wq_train_X.columns[(sel.get_support())]\r\n",
        "print(selected_feat) #['volatile acidity', 'density', 'alcohol']"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['volatile acidity', 'density', 'alcohol'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cehxJsm5c-Tm"
      },
      "source": [
        "#extract top 10 best features for predicting wine quality - option1:SelectKBest class\r\n",
        "# source: https://thecleverprogrammer.com/2020/06/30/feature-selection-techniques-in-machine-learning-with-python/\r\n",
        "from sklearn.feature_selection import SelectKBest\r\n",
        "from sklearn.feature_selection import chi2\r\n",
        "\r\n",
        "bestfeatures = SelectKBest(score_func=chi2, k=10)\r\n",
        "fit = bestfeatures.fit(X,y)\r\n",
        "dfscores = pd.DataFrame(fit.scores_)\r\n",
        "dfcolumns = pd.DataFrame(X.columns)\r\n",
        "#concat two dataframes for better visualization \r\n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\r\n",
        "featureScores.columns = ['Features','Score']  #naming the dataframe columns\r\n",
        "print(featureScores.nlargest(10,'Score'))\r\n",
        "\r\n",
        "# top5: total sulfur dioxide, free sulfur dioxide, alcohol, volatile acidity, residual sugar\r\n",
        "\r\n",
        "#output\r\n",
        "#Features       Score\r\n",
        "#6   total sulfur dioxide  431.709881\r\n",
        "#5    free sulfur dioxide  212.255709\r\n",
        "#10               alcohol  151.229253\r\n",
        "#1       volatile acidity   37.105396\r\n",
        "#3         residual sugar   28.531646\r\n",
        "#0          fixed acidity    9.439111\r\n",
        "#4              chlorides    5.110229\r\n",
        "#2            citric acid    2.500478\r\n",
        "#9              sulphates    0.572889\r\n",
        "#8                     pH    0.019861"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dk8BsuCh7TE"
      },
      "source": [
        "# train and predict a model - LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu9SN5jhcmTj",
        "outputId": "2b7c3b85-d3ad-49dc-b6d7-29179a42ca0f"
      },
      "source": [
        "# define parameters of the logisitic regression model \r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\r\n",
        "intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\r\n",
        "penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\r\n",
        "verbose=0, warm_start=False)\r\n",
        "\r\n",
        "# =======train a model : fit the Logistic Regression classifier\r\n",
        "wq_lr = LogisticRegression()\r\n",
        "wq_lr.fit(wq_train_X, wq_train_y)\r\n",
        "wq_lr.score(wq_test_X, wq_test_y)\r\n",
        "\r\n",
        "# =======predict the wine type and evaluate the performance\r\n",
        "wq_lr_predictions = wq_lr.predict(wq_test_X)\r\n",
        "#print(classification_report(wq_test_y,wq_lr_predictions, target_names=['red', 'white']))\r\n",
        "print(classification_report(wq_test_y,wq_lr_predictions))\r\n",
        "\r\n",
        "#from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\r\n",
        "#confusion_matrix(y_test, ypred)\r\n",
        "#classification_report(y_test, ypred)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        high       0.00      0.00      0.00        54\n",
            "         low       0.62      0.56      0.59       718\n",
            "      medium       0.72      0.79      0.75      1178\n",
            "\n",
            "    accuracy                           0.68      1950\n",
            "   macro avg       0.44      0.45      0.45      1950\n",
            "weighted avg       0.66      0.68      0.67      1950\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP97zmFsjhID",
        "outputId": "78cc415b-c238-4f87-a1a7-96b6a3a5a3b3"
      },
      "source": [
        "accuracy_score(wq_test_y,wq_lr_predictions) #0.6815384615384615"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6815384615384615"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r70srdxuiZox"
      },
      "source": [
        "# train and preidct a model - random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYIubdoIiQUG",
        "outputId": "557377ac-32e3-44dc-afa2-2123cf1272d6"
      },
      "source": [
        "#Train the random forests model\r\n",
        "#wq_train_X, wq_test_X, wq_train_y, wq_test_y\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "\r\n",
        "random_forest_model = RandomForestClassifier()\r\n",
        "random_forest_model.fit(wq_train_X, wq_train_y)\r\n",
        "wq_rf_predictions = random_forest_model.predict(wq_test_X)\r\n",
        "\r\n",
        "#Measure the performance of the random forest model\r\n",
        "\r\n",
        "print(classification_report(wq_test_y, wq_rf_predictions))\r\n",
        "print(confusion_matrix(wq_test_y, wq_rf_predictions))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        high       0.94      0.28      0.43        54\n",
            "         low       0.78      0.71      0.75       718\n",
            "      medium       0.81      0.88      0.84      1178\n",
            "\n",
            "    accuracy                           0.80      1950\n",
            "   macro avg       0.84      0.62      0.67      1950\n",
            "weighted avg       0.80      0.80      0.80      1950\n",
            "\n",
            "[[  15    2   37]\n",
            " [   0  513  205]\n",
            " [   1  144 1033]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bmNJpKFj56D",
        "outputId": "61234c28-1d25-468c-bb4e-79a8615ed3b0"
      },
      "source": [
        "accuracy_score(wq_test_y,wq_rf_predictions) #0.8005128205128205"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8005128205128205"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xggh_760sKC_"
      },
      "source": [
        "# compare algorithms based on accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPtyP-AAsJbK"
      },
      "source": [
        "# Compare Algorithms\r\n",
        "from sklearn import model_selection\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.svm import SVC\r\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjsgmM0bu8xd"
      },
      "source": [
        "# load dataset\r\n",
        "X = X\r\n",
        "Y = y \r\n",
        "\r\n",
        "# prepare configuration for cross validation test harness\r\n",
        "seed = 7\r\n",
        "# prepare models\r\n",
        "models = []\r\n",
        "models.append(('LR', LogisticRegression()))\r\n",
        "#models.append(('LDA', LinearDiscriminantAnalysis()))\r\n",
        "models.append(('KNN', KNeighborsClassifier(n_neighbors = 20)))\r\n",
        "models.append(('RF', RandomForestClassifier()))\r\n",
        "models.append(('CART', DecisionTreeClassifier()))\r\n",
        "#models.append(('NB', GaussianNB()))\r\n",
        "models.append(('SVM', SVC()))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJCzptrcwqOV"
      },
      "source": [
        "# evaluate each model in turn - wine_quality\r\n",
        "results = []\r\n",
        "names = []\r\n",
        "scoring = 'accuracy'\r\n",
        "for name, model in models:\r\n",
        "\tkfold = model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\r\n",
        "\tcv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\r\n",
        "\tresults.append(cv_results)\r\n",
        "\tnames.append(name)\r\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\r\n",
        "\tprint(msg)\r\n",
        " \r\n",
        "# boxplot algorithm comparison\r\n",
        "fig = plt.figure()\r\n",
        "fig.suptitle('Algorithm Comparison')\r\n",
        "ax = fig.add_subplot(111)\r\n",
        "plt.boxplot(results)\r\n",
        "ax.set_xticklabels(names)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "#Output\r\n",
        "#LR: 0.679856 (0.015070)\r\n",
        "#KNN: 0.647381 (0.017921)\r\n",
        "#RF: 0.820534 (0.011657)\r\n",
        "#CART: 0.749419 (0.017380)\r\n",
        "#SVM: 0.603201 (0.021367)\r\n",
        "#> RF is the winner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKdvCY_FktbM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52Kt-dZkktfo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grslury_ktik"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xv4G5Kh_pSm"
      },
      "source": [
        "# regression - using k-nearest neighbors model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRgP-cW5_o1H"
      },
      "source": [
        "# code source: https://www.datatechnotes.com/2019/04/regression-example-with-k-nearest.html\r\n",
        "\r\n",
        "# prepare dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xn7jnbO_znA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56076481-e0eb-4906-d8bb-153b22dc2775"
      },
      "source": [
        "#Train the knn model\r\n",
        "from sklearn.metrics import mean_squared_error \r\n",
        "from sklearn.neighbors import KNeighborsRegressor\r\n",
        "\r\n",
        "K = 8 \r\n",
        "wq_knn_reg = KNeighborsRegressor(n_neighbors=K)\r\n",
        "print(wq_knn_reg)\r\n",
        "\r\n",
        "KNeighborsRegressor(algorithm='auto', leaf_size=30, \r\n",
        "          metric_params=None, n_jobs=1, n_neighbors=8, p=2,\r\n",
        "          weights='uniform') \r\n",
        "\r\n",
        "wq_knn_reg.fit(wq_train_X, wq_train_y)\r\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                    metric_params=None, n_jobs=None, n_neighbors=8, p=2,\n",
            "                    weights='uniform')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                    metric_params=None, n_jobs=None, n_neighbors=8, p=2,\n",
              "                    weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0VFffpLAUwI"
      },
      "source": [
        "# =======predict the wine type and evaluate the performance\r\n",
        "wq_knn_reg_pred = wq_knn_reg.predict(wq_test_X)\r\n",
        "\r\n",
        "#i don't know how to solve this problem and have no time anymore today"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QTmzDMqljBs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5W_d9UPEo9c"
      },
      "source": [
        "# regression - using random forest model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW0THWiCEAzO"
      },
      "source": [
        "# source: https://www.datatechnotes.com/2020/09/regression-example-with-randomforestregressor.html\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiGs_XA7EA2c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l46s1ahcEA5J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}