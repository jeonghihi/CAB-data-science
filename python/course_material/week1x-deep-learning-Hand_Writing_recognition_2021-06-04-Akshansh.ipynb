{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hand_Writing_recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_hzfVFMmU2E"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyV7Pipqt2mp"
      },
      "source": [
        "#mnist dataset : https://keras.io/api/datasets/mnist/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j6DWnMTtFv4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5elUylJmaJf"
      },
      "source": [
        "(x_train, y_train) ,(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# try this data :| \n",
        "# (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETAyQ0dbNJ7s",
        "outputId": "d2fa0342-f9a5-43d3-ff57-dc8081573e39"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKRgK7WmhfZI",
        "outputId": "bea0d36e-3b0f-41d4-827f-0a09b598cd9e"
      },
      "source": [
        "x_train[0].shape\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez9SG1AXNJuR",
        "outputId": "02d62af9-ab76-4503-9af4-8c48280dee9e"
      },
      "source": [
        "y_train = y_train[..., np.newaxis]\n",
        "y_test = y_test[..., np.newaxis]\n",
        "y_train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "pThJv4NosXh7",
        "outputId": "74da52f2-1284-40cd-a525-831defd3f4e4"
      },
      "source": [
        "plt.imshow(x_train[4]) # 28 X 28 images"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f39551bf3d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1j5XolusaPt",
        "outputId": "cf1c2d75-3bcf-49e1-fae3-3132887edfa0"
      },
      "source": [
        "y_train[4]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOkpkAJsx8rP"
      },
      "source": [
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iR8Y245zqWH"
      },
      "source": [
        "#x_train[0].  ## convolutional layers for computer vision"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsMKwvu3jdYx",
        "outputId": "7a27c996-0dfb-4ec8-804c-7bf67cb9b2c2"
      },
      "source": [
        "# [[1,2,3]\n",
        "#  [4,5,6]]\n",
        "\n",
        "#  [1,2,3,4,5,6]  \n",
        "\n",
        "28*28"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_EIQaSnzDLA"
      },
      "source": [
        "## Flatten: Used to convert N-D array to 1D -arrays\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WASzwylEujqO"
      },
      "source": [
        "model = models.Sequential(\n",
        "    [\n",
        "    layers.Flatten(input_shape = (28,28)),\n",
        "    layers.Dense(64, activation = 'relu', name = 'first_layer'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(64, activation = 'relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(10, activation = 'softmax' )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Dropout, optimizer, sparse_categorical_crossentropy\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam',    # rmsprop, sgd\n",
        "    loss = 'sparse_categorical_crossentropy',  # binary_crossentropy, categorical_crossentropy\n",
        "    metrics = ['accuracy', 'mse']\n",
        ")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XGqCrxWlouw"
      },
      "source": [
        "# categorical_crossentropy: true labels: [0 0 1], [0 1 0], [0 0 1] ,:  predicted : [0 0 1], [1 0 0], [0 0 1]\n",
        "\n",
        "# sparse_categorical_crossentropy: true label: 2, 1, 2 : predicted : [0 0 1], [1 0 0], [0 0 1]\n",
        "\n",
        "\n",
        "#\n",
        "\n",
        "\n",
        "# categorical_crossentropy:       0 :  [1 0 0 0 0 0 0 0 0 0 0]\n",
        "# sparse_categorical_crossentropy 1 :  [0 1 0 0 0 0 0 0 0 0 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yt5uoK5yZeT",
        "outputId": "b2df7adc-1f7b-484d-e3f6-0d047b4fd820"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "first_layer (Dense)          (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 55,050\n",
            "Trainable params: 55,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxV4SgU1xDXq",
        "outputId": "c9e84ecb-7f31-42c2-f35b-884333f5ee41"
      },
      "source": [
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 10,\n",
        "    batch_size = 128\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0953 - accuracy: 0.9704 - mse: 27.3896\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0934 - accuracy: 0.9711 - mse: 27.3896\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0892 - accuracy: 0.9714 - mse: 27.3899\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0890 - accuracy: 0.9715 - mse: 27.3899\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0864 - accuracy: 0.9727 - mse: 27.3901\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0813 - accuracy: 0.9744 - mse: 27.3903\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0796 - accuracy: 0.9743 - mse: 27.3903\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0771 - accuracy: 0.9753 - mse: 27.3905\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0753 - accuracy: 0.9749 - mse: 27.3905\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0735 - accuracy: 0.9755 - mse: 27.3906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f39504cd510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZy9uPbwyL_Q",
        "outputId": "00f3def4-f301-4ee5-b669-cfc718670085"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0840 - accuracy: 0.9753 - mse: 27.3380\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08403781801462173, 0.9753000140190125, 27.337987899780273]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTAYuccXzB9H",
        "outputId": "be52b0e3-e808-4bb4-e292-46d2cde7c8f1"
      },
      "source": [
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 10,\n",
        "    batch_size = 128,\n",
        "    validation_split = 0.15\n",
        ")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "399/399 [==============================] - 2s 5ms/step - loss: 0.5921 - accuracy: 0.8196 - mse: 27.3429 - val_loss: 0.1969 - val_accuracy: 0.9439 - val_mse: 27.4918\n",
            "Epoch 2/10\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.2707 - accuracy: 0.9200 - mse: 27.3603 - val_loss: 0.1466 - val_accuracy: 0.9577 - val_mse: 27.4958\n",
            "Epoch 3/10\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.2122 - accuracy: 0.9377 - mse: 27.3639 - val_loss: 0.1216 - val_accuracy: 0.9631 - val_mse: 27.4973\n",
            "Epoch 4/10\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1819 - accuracy: 0.9469 - mse: 27.3655 - val_loss: 0.1091 - val_accuracy: 0.9669 - val_mse: 27.4984\n",
            "Epoch 5/10\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1582 - accuracy: 0.9517 - mse: 27.3666 - val_loss: 0.1023 - val_accuracy: 0.9707 - val_mse: 27.4992\n",
            "Epoch 6/10\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1469 - accuracy: 0.9556 - mse: 27.3673 - val_loss: 0.0973 - val_accuracy: 0.9707 - val_mse: 27.4994\n",
            "Epoch 7/10\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1346 - accuracy: 0.9587 - mse: 27.3681 - val_loss: 0.0912 - val_accuracy: 0.9726 - val_mse: 27.4997\n",
            "Epoch 8/10\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1249 - accuracy: 0.9613 - mse: 27.3686 - val_loss: 0.0886 - val_accuracy: 0.9742 - val_mse: 27.5001\n",
            "Epoch 9/10\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1172 - accuracy: 0.9639 - mse: 27.3689 - val_loss: 0.0915 - val_accuracy: 0.9719 - val_mse: 27.5002\n",
            "Epoch 10/10\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1139 - accuracy: 0.9651 - mse: 27.3692 - val_loss: 0.0868 - val_accuracy: 0.9739 - val_mse: 27.5006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f39501d3d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcC9Lovxzzwv",
        "outputId": "a6a66c7f-38e1-460c-fe91-d419f1fa3a01"
      },
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 20,\n",
        "    batch_size = 128,\n",
        "    validation_split = 0.15\n",
        ")\n",
        "\n",
        "# in Machine Learning: train - test\n",
        "# in deep learning: train - validation - test"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "399/399 [==============================] - 39s 5ms/step - loss: 0.5788 - accuracy: 0.8247 - mse: 27.3432 - val_loss: 0.1981 - val_accuracy: 0.9446 - val_mse: 27.4919\n",
            "Epoch 2/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.2726 - accuracy: 0.9201 - mse: 27.3603 - val_loss: 0.1483 - val_accuracy: 0.9558 - val_mse: 27.4954\n",
            "Epoch 3/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.2160 - accuracy: 0.9349 - mse: 27.3634 - val_loss: 0.1257 - val_accuracy: 0.9636 - val_mse: 27.4976\n",
            "Epoch 4/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1823 - accuracy: 0.9447 - mse: 27.3653 - val_loss: 0.1106 - val_accuracy: 0.9688 - val_mse: 27.4986\n",
            "Epoch 5/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1622 - accuracy: 0.9502 - mse: 27.3665 - val_loss: 0.1014 - val_accuracy: 0.9704 - val_mse: 27.4994\n",
            "Epoch 6/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1465 - accuracy: 0.9556 - mse: 27.3674 - val_loss: 0.1001 - val_accuracy: 0.9707 - val_mse: 27.4997\n",
            "Epoch 7/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1348 - accuracy: 0.9588 - mse: 27.3680 - val_loss: 0.0957 - val_accuracy: 0.9724 - val_mse: 27.4998\n",
            "Epoch 8/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1237 - accuracy: 0.9613 - mse: 27.3685 - val_loss: 0.0931 - val_accuracy: 0.9726 - val_mse: 27.5004\n",
            "Epoch 9/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1183 - accuracy: 0.9624 - mse: 27.3688 - val_loss: 0.0864 - val_accuracy: 0.9733 - val_mse: 27.5004\n",
            "Epoch 10/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1135 - accuracy: 0.9639 - mse: 27.3692 - val_loss: 0.0881 - val_accuracy: 0.9738 - val_mse: 27.5005\n",
            "Epoch 11/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1051 - accuracy: 0.9665 - mse: 27.3696 - val_loss: 0.0871 - val_accuracy: 0.9753 - val_mse: 27.5005\n",
            "Epoch 12/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1005 - accuracy: 0.9678 - mse: 27.3698 - val_loss: 0.0870 - val_accuracy: 0.9753 - val_mse: 27.5009\n",
            "Epoch 13/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.0980 - accuracy: 0.9689 - mse: 27.3700 - val_loss: 0.0826 - val_accuracy: 0.9752 - val_mse: 27.5009\n",
            "Epoch 14/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.0901 - accuracy: 0.9712 - mse: 27.3703 - val_loss: 0.0827 - val_accuracy: 0.9757 - val_mse: 27.5011\n",
            "Epoch 15/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.0896 - accuracy: 0.9720 - mse: 27.3706 - val_loss: 0.0826 - val_accuracy: 0.9768 - val_mse: 27.5011\n",
            "Epoch 16/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.0868 - accuracy: 0.9727 - mse: 27.3706 - val_loss: 0.0878 - val_accuracy: 0.9750 - val_mse: 27.5011\n",
            "Epoch 17/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.0843 - accuracy: 0.9732 - mse: 27.3707 - val_loss: 0.0778 - val_accuracy: 0.9757 - val_mse: 27.5012\n",
            "Epoch 18/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.0810 - accuracy: 0.9742 - mse: 27.3708 - val_loss: 0.0806 - val_accuracy: 0.9771 - val_mse: 27.5014\n",
            "Epoch 19/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.0790 - accuracy: 0.9751 - mse: 27.3710 - val_loss: 0.0861 - val_accuracy: 0.9756 - val_mse: 27.5015\n",
            "Epoch 20/20\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.0758 - accuracy: 0.9753 - mse: 27.3711 - val_loss: 0.0819 - val_accuracy: 0.9761 - val_mse: 27.5014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "tUTy3cQD0lBI",
        "outputId": "b3563923-7584-4d2a-ec29-8773c6ee1e55"
      },
      "source": [
        "df = pd.DataFrame(history.history)\n",
        "df"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>mse</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.578777</td>\n",
              "      <td>0.824726</td>\n",
              "      <td>27.343216</td>\n",
              "      <td>0.198051</td>\n",
              "      <td>0.944556</td>\n",
              "      <td>27.491928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.272591</td>\n",
              "      <td>0.920118</td>\n",
              "      <td>27.360336</td>\n",
              "      <td>0.148298</td>\n",
              "      <td>0.955778</td>\n",
              "      <td>27.495443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.216033</td>\n",
              "      <td>0.934902</td>\n",
              "      <td>27.363432</td>\n",
              "      <td>0.125674</td>\n",
              "      <td>0.963556</td>\n",
              "      <td>27.497629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.182346</td>\n",
              "      <td>0.944706</td>\n",
              "      <td>27.365307</td>\n",
              "      <td>0.110632</td>\n",
              "      <td>0.968778</td>\n",
              "      <td>27.498562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.162195</td>\n",
              "      <td>0.950176</td>\n",
              "      <td>27.366541</td>\n",
              "      <td>0.101368</td>\n",
              "      <td>0.970444</td>\n",
              "      <td>27.499369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.146505</td>\n",
              "      <td>0.955608</td>\n",
              "      <td>27.367371</td>\n",
              "      <td>0.100131</td>\n",
              "      <td>0.970667</td>\n",
              "      <td>27.499723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.134763</td>\n",
              "      <td>0.958804</td>\n",
              "      <td>27.368029</td>\n",
              "      <td>0.095662</td>\n",
              "      <td>0.972444</td>\n",
              "      <td>27.499844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.123693</td>\n",
              "      <td>0.961333</td>\n",
              "      <td>27.368513</td>\n",
              "      <td>0.093119</td>\n",
              "      <td>0.972556</td>\n",
              "      <td>27.500389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.118283</td>\n",
              "      <td>0.962431</td>\n",
              "      <td>27.368843</td>\n",
              "      <td>0.086425</td>\n",
              "      <td>0.973333</td>\n",
              "      <td>27.500355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.113528</td>\n",
              "      <td>0.963922</td>\n",
              "      <td>27.369198</td>\n",
              "      <td>0.088101</td>\n",
              "      <td>0.973778</td>\n",
              "      <td>27.500460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.105132</td>\n",
              "      <td>0.966490</td>\n",
              "      <td>27.369583</td>\n",
              "      <td>0.087095</td>\n",
              "      <td>0.975333</td>\n",
              "      <td>27.500458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.100468</td>\n",
              "      <td>0.967843</td>\n",
              "      <td>27.369839</td>\n",
              "      <td>0.087039</td>\n",
              "      <td>0.975333</td>\n",
              "      <td>27.500914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.097999</td>\n",
              "      <td>0.968863</td>\n",
              "      <td>27.370022</td>\n",
              "      <td>0.082634</td>\n",
              "      <td>0.975222</td>\n",
              "      <td>27.500944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.090142</td>\n",
              "      <td>0.971196</td>\n",
              "      <td>27.370262</td>\n",
              "      <td>0.082714</td>\n",
              "      <td>0.975667</td>\n",
              "      <td>27.501104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.089568</td>\n",
              "      <td>0.971961</td>\n",
              "      <td>27.370560</td>\n",
              "      <td>0.082585</td>\n",
              "      <td>0.976778</td>\n",
              "      <td>27.501064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.086765</td>\n",
              "      <td>0.972686</td>\n",
              "      <td>27.370617</td>\n",
              "      <td>0.087831</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>27.501093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.084346</td>\n",
              "      <td>0.973157</td>\n",
              "      <td>27.370665</td>\n",
              "      <td>0.077810</td>\n",
              "      <td>0.975667</td>\n",
              "      <td>27.501196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.081029</td>\n",
              "      <td>0.974196</td>\n",
              "      <td>27.370781</td>\n",
              "      <td>0.080592</td>\n",
              "      <td>0.977111</td>\n",
              "      <td>27.501421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.079045</td>\n",
              "      <td>0.975137</td>\n",
              "      <td>27.370964</td>\n",
              "      <td>0.086067</td>\n",
              "      <td>0.975556</td>\n",
              "      <td>27.501459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.075763</td>\n",
              "      <td>0.975275</td>\n",
              "      <td>27.371119</td>\n",
              "      <td>0.081863</td>\n",
              "      <td>0.976111</td>\n",
              "      <td>27.501352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy        mse  val_loss  val_accuracy    val_mse\n",
              "0   0.578777  0.824726  27.343216  0.198051      0.944556  27.491928\n",
              "1   0.272591  0.920118  27.360336  0.148298      0.955778  27.495443\n",
              "2   0.216033  0.934902  27.363432  0.125674      0.963556  27.497629\n",
              "3   0.182346  0.944706  27.365307  0.110632      0.968778  27.498562\n",
              "4   0.162195  0.950176  27.366541  0.101368      0.970444  27.499369\n",
              "5   0.146505  0.955608  27.367371  0.100131      0.970667  27.499723\n",
              "6   0.134763  0.958804  27.368029  0.095662      0.972444  27.499844\n",
              "7   0.123693  0.961333  27.368513  0.093119      0.972556  27.500389\n",
              "8   0.118283  0.962431  27.368843  0.086425      0.973333  27.500355\n",
              "9   0.113528  0.963922  27.369198  0.088101      0.973778  27.500460\n",
              "10  0.105132  0.966490  27.369583  0.087095      0.975333  27.500458\n",
              "11  0.100468  0.967843  27.369839  0.087039      0.975333  27.500914\n",
              "12  0.097999  0.968863  27.370022  0.082634      0.975222  27.500944\n",
              "13  0.090142  0.971196  27.370262  0.082714      0.975667  27.501104\n",
              "14  0.089568  0.971961  27.370560  0.082585      0.976778  27.501064\n",
              "15  0.086765  0.972686  27.370617  0.087831      0.975000  27.501093\n",
              "16  0.084346  0.973157  27.370665  0.077810      0.975667  27.501196\n",
              "17  0.081029  0.974196  27.370781  0.080592      0.977111  27.501421\n",
              "18  0.079045  0.975137  27.370964  0.086067      0.975556  27.501459\n",
              "19  0.075763  0.975275  27.371119  0.081863      0.976111  27.501352"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "88uQiK8T0yiv",
        "outputId": "58d5eeef-8417-476b-9b15-f670cf57c8e8"
      },
      "source": [
        "df.plot(y = 'val_accuracy')\n",
        "df.plot(y = 'accuracy')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f39059b5190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyDiC1yg1MfT"
      },
      "source": [
        "y = model.predict(x_test[0:1])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RMMO-1V3ECP",
        "outputId": "ae654f2d-cbe2-4855-922b-30303a0e547f"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.3147031e-08, 1.7291875e-07, 7.3216456e-06, 3.8334334e-04,\n",
              "        2.7177655e-10, 6.3254276e-08, 2.0839318e-12, 9.9960154e-01,\n",
              "        4.8004799e-06, 2.7260569e-06]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONOAuzvs3JGd",
        "outputId": "47ee84ba-d941-493e-881b-8c5df13afdc8"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNWjHOXc1kWR",
        "outputId": "4ca260f6-8353-49a6-d2bd-5a92c66b649c"
      },
      "source": [
        "tf.argmax(y, axis=-1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([7])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "99jxaDUW1l5v",
        "outputId": "697bf4bf-481c-410d-ffb0-7702c5acab50"
      },
      "source": [
        "plt.imshow(x_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f956267cbd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ToYF24c2Roz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b1b3a0f4-bc82-4558-c025-e58f1c579364"
      },
      "source": [
        "plt.imshow(x_test[5])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3905548e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Gy0h1ytb6A"
      },
      "source": [
        "# CallBAcks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO_YG1LYtgTH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G01pXXttjp8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3bLYmrRtj8m",
        "outputId": "1dc498f7-a3dd-4546-bf4b-6972f2be5a1d"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 30,\n",
        "    batch_size = 128,\n",
        "    validation_split = .15,\n",
        "    callbacks = [EarlyStopping(patience= 2)]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.6330 - accuracy: 0.8174 - val_loss: 0.1478 - val_accuracy: 0.9589\n",
            "Epoch 2/30\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.1492 - accuracy: 0.9556 - val_loss: 0.1148 - val_accuracy: 0.9670\n",
            "Epoch 3/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9709 - val_loss: 0.0928 - val_accuracy: 0.9720\n",
            "Epoch 4/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0721 - accuracy: 0.9775 - val_loss: 0.0853 - val_accuracy: 0.9743\n",
            "Epoch 5/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0499 - accuracy: 0.9855 - val_loss: 0.0787 - val_accuracy: 0.9768\n",
            "Epoch 6/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0386 - accuracy: 0.9890 - val_loss: 0.0826 - val_accuracy: 0.9756\n",
            "Epoch 7/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9900 - val_loss: 0.0770 - val_accuracy: 0.9787\n",
            "Epoch 8/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 0.0823 - val_accuracy: 0.9780\n",
            "Epoch 9/30\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 0.0955 - val_accuracy: 0.9756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f95625bd150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRvp6QxYtkMn"
      },
      "source": [
        "#callbacks = [tf.keras.callbacks.EarlyStopping()]  patience \n",
        "# Arguments: 1) patience = 0 (def), 2) monitor = 'val_loss' (default) 3) min_delta = 0.01 (measure of improvement), 4) mode = 'auto'. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INczJKgsuV9g",
        "outputId": "5a95fd56-0847-4eab-9deb-77617667510d"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "path = 'hamdwriting/model_weights'\n",
        "checkpoint = ModelCheckpoint(filepath = path,\n",
        "                             frequency = 'epoch',\n",
        "                             save_weights_only = True,\n",
        "                             save_best_only = True,\n",
        "                             verbose =1\n",
        "                          )\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 25,\n",
        "    batch_size = 128,\n",
        "    validation_split = .15,\n",
        "    callbacks = [EarlyStopping(patience= 2), checkpoint]\n",
        "\n",
        "\n",
        ")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "399/399 [==============================] - 2s 5ms/step - loss: 0.5979 - accuracy: 0.8199 - mse: 27.3424 - val_loss: 0.2086 - val_accuracy: 0.9404 - val_mse: 27.4906\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.20863, saving model to hamdwriting/model_weights\n",
            "Epoch 2/25\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.2810 - accuracy: 0.9161 - mse: 27.3596 - val_loss: 0.1507 - val_accuracy: 0.9562 - val_mse: 27.4953\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.20863 to 0.15070, saving model to hamdwriting/model_weights\n",
            "Epoch 3/25\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.2222 - accuracy: 0.9333 - mse: 27.3631 - val_loss: 0.1269 - val_accuracy: 0.9634 - val_mse: 27.4970\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.15070 to 0.12686, saving model to hamdwriting/model_weights\n",
            "Epoch 4/25\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1885 - accuracy: 0.9435 - mse: 27.3650 - val_loss: 0.1140 - val_accuracy: 0.9671 - val_mse: 27.4983\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.12686 to 0.11396, saving model to hamdwriting/model_weights\n",
            "Epoch 5/25\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1680 - accuracy: 0.9485 - mse: 27.3661 - val_loss: 0.1074 - val_accuracy: 0.9698 - val_mse: 27.4990\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.11396 to 0.10735, saving model to hamdwriting/model_weights\n",
            "Epoch 6/25\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1484 - accuracy: 0.9551 - mse: 27.3673 - val_loss: 0.1012 - val_accuracy: 0.9726 - val_mse: 27.4994\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.10735 to 0.10116, saving model to hamdwriting/model_weights\n",
            "Epoch 7/25\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1387 - accuracy: 0.9576 - mse: 27.3678 - val_loss: 0.0944 - val_accuracy: 0.9718 - val_mse: 27.4998\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.10116 to 0.09439, saving model to hamdwriting/model_weights\n",
            "Epoch 8/25\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1278 - accuracy: 0.9605 - mse: 27.3683 - val_loss: 0.0942 - val_accuracy: 0.9738 - val_mse: 27.5002\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.09439 to 0.09417, saving model to hamdwriting/model_weights\n",
            "Epoch 9/25\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1222 - accuracy: 0.9620 - mse: 27.3687 - val_loss: 0.0915 - val_accuracy: 0.9749 - val_mse: 27.5003\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.09417 to 0.09149, saving model to hamdwriting/model_weights\n",
            "Epoch 10/25\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1153 - accuracy: 0.9645 - mse: 27.3691 - val_loss: 0.0876 - val_accuracy: 0.9753 - val_mse: 27.5005\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.09149 to 0.08757, saving model to hamdwriting/model_weights\n",
            "Epoch 11/25\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1094 - accuracy: 0.9656 - mse: 27.3694 - val_loss: 0.0892 - val_accuracy: 0.9746 - val_mse: 27.5005\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.08757\n",
            "Epoch 12/25\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.1018 - accuracy: 0.9681 - mse: 27.3697 - val_loss: 0.0921 - val_accuracy: 0.9744 - val_mse: 27.5007\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.08757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f390570cf90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n22slxQ_uWA0",
        "outputId": "e5d2c6c0-c6bc-43d1-a465-817d186849df"
      },
      "source": [
        "! ls hamdwriting"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint  model_weights.data-00000-of-00001  model_weights.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "ibt2DjCkD8Kn",
        "outputId": "17507b8c-aa5d-4ad3-d217-8ca4c74e0e9a"
      },
      "source": [
        "model_weights.data-00000-of-00001"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-53-bcab91a0bb2d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model_weights.data-00000-of-00001\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid token\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFvP74eZuWEh",
        "outputId": "36cc7ef1-cd8c-4a86-961e-66b638689e02"
      },
      "source": [
        "model.load_weights(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f95622e8750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz1hqq7rDpY9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBuEVrCSDqKs"
      },
      "source": [
        "### Atready saved model in tensorflow: Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_FayM-uwVSc"
      },
      "source": [
        "from tensorflow.keras.applications import InceptionV3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJxtYXd87QFt",
        "outputId": "89720c5d-777d-4511-fbf0-06ef661bbbfc"
      },
      "source": [
        "model = InceptionV3()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1CpMbLP7UMm",
        "outputId": "5ec53d0b-efb5-49d3-f2a2-7be47d759930"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,851,784\n",
            "Trainable params: 23,817,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCadepp57XHa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}